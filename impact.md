% Don't be afraid of Open Access
% List of authors to be determined
% ...

In a recent Letter, [@agrawal2014] raises four reasons why scientists should be skeptical of the Open Access (OA) movement, including the fact that
publishing in OA journals can *lower* one's impact. Before we present a
dissenting view, we feel like clarifying some mis-conceptions is in order. OA
is a mode of diffusion of scientific literature in which the authors, or
their home institution, buys back the rights of an article from the publisher,
so that the article is free to access. It is generally agreed that the
article is free, to use a metaphor from software development, "as in beer"
(*i.e.* there is no need to pay for it), and "as in speech" (*i.e.* there
are minimal limits to its reproduction, re-use, and possibly modification).

That some "predatory" publishers are taking advantage of this model
to generate a profit is undeniable. However, such journals well identified,
and easy to avoid and frequently updated list of predatory publishers [@Beall2014] is readily available online for easy reference. In itself, OA is not built on whether a profit will be made (many non-OA journals, especially ones operated by societies, are for-profit), but on the making the output of research available to the largest possible number of readers. The fact that OA journals are not necessarily *non-selective* has been covered in the response by Lanford & Pennel's response, so we will not elaborate on this point any further.

[@agrawal2014] raises two points against OA that are of particular relevance for early career scientists. First, the impact factor of OA journals is not higher than the impact factor of non-OA journals. Second, it is tempting to use the journal as a surrogate for the quality of a paper, and less prestigious OA journals run a risk of seeing good papers viewed less favorably.<!-- This sentence is so oddly written. Here is an attempt at a rewrite.:
Secondly, it is tempting to use a journals impact factor as a proxy for the quality of a paper, and therefore, high quaility research published in a less prestigious OA journals runs the risk of being perceived less favorably.
 --> We do not think that any of these <!-- delete: points --> are valid arguments against open access.

First, the <!-- strong? --> distinction between OA and non-OA journals is a false
dichotomy. Although there are journals applying an open access (often of the
*Creative Commons* variety) to all articles they publish, an increasing number
of publishers allow authors to pay a *per* article OA license to retain their
copyright, and so there exists a continuum between pure-OA, mixed-models,
and closed journals. Even though, the notion that pure-OA journals have
a lower impact is challenged by some. James Pringle of Thomson ISI (i)
recognizes that the relevance of journals when talking about OA is dubious
and (ii) "prospective authors should not fear publishing in these journals"
[http://www.nature.com/nature/focus/accessdebate/19.html].

Second, the fact that OA journals carry less prestige is not a problem with
the OA movement. Measures of journal impact are known to be extremely biased
by a few papers concentrating a few citations, and cannot possibly be used to
estimate the quality of a paper, let alone its *future impact*. Simply put,
the impact factor of a journal is not the expected number of citations any single paper is expected to receive. If rigor is important to us, then it is unacceptable to think that a paper is bad because it was published in a less respectable journal, or that a paper is good because it merely because it was published in a highly selective journal; the same paper can be just as impactful whether published in *PLoS One* or *Nature*. This point strikes us as a demonstration that the metrics currently used for evaluations are biased. One promising new development to address this issue are *article-level* metrics [needs a citation, possibly from Martin Fenner], which provides a way to measure the impact of an article regardless of what journal it appeared in. We think that rather than pushing against the OA model, we should have a discussion about how these new measurescan be used in to objectively evaluate research output.

[@agrawal2014] concludes his paper on the need to find *an alternative model of
publishing that suits the primary goals of scientists*. On that, we could not
agree more. However, what that *primary goal* is seems open to debate. We
would like to make the point that, particularly in ecology and environmental
sciences, the primary goal of research should be to produce fundamental insights that can be mobilized to solve large scale problems. Making information flow freely between scientists, policy-makers, and stakeholders is paramount to this effort. What does not strikes us as a *primary* goal, is the maximization of self-aggrandizing, not to mention arbitrary, measures of impact.

## Literature Cited


